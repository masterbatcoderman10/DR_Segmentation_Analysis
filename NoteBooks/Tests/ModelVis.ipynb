{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhtar/opt/anaconda3/envs/condatorch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel():\n",
    "\n",
    "    def predict(self, dataloader):\n",
    "        \"\"\"This function returns the predictions for all images present in the dataloader\"\"\"\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            predictions = []\n",
    "            for images, _ in tqdm(dataloader):\n",
    "                images = images.to(device)\n",
    "                outputs = self(images)\n",
    "                outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                predictions.append(outputs.permute(0, 2, 3, 1))\n",
    "            predictions = torch.cat(predictions, dim=0)\n",
    "        \n",
    "        return predictions.detach().cpu().numpy()\n",
    "    \n",
    "    def predict_image(self, image):\n",
    "        \"\"\"This function returns the prediction of one image\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            image = image.unsqueeze(0)\n",
    "            image = image.to(device)\n",
    "            output = self(image)\n",
    "            output = torch.nn.functional.softmax(output, dim=1)\n",
    "            output = output.detach().cpu().numpy()\n",
    "            output = np.transpose(output, (0, 2, 3, 1))\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.upconv = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self.conv_1 = nn.Conv2d(d_in, d_out, 1, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_2 = nn.Conv2d(d_out*2, d_out, 3, 1, \"same\")\n",
    "        self.conv_3 = nn.Conv2d(d_out, d_out, 3, 1, \"same\")\n",
    "\n",
    "    def forward(self, inp, a):\n",
    "\n",
    "        x = self.upconv(inp)\n",
    "        x = self.relu(self.conv_1(x))\n",
    "\n",
    "        if a is not None:\n",
    "            x = torch.cat([a, x], axis=1)\n",
    "            x = self.relu(self.conv_2(x))\n",
    "            \n",
    "        x = self.relu(self.conv_3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "        self.upconv = nn.ConvTranspose2d(d_in, d_out, 3, 2, padding=1)\n",
    "        self.conv_1 = nn.Conv2d(d_out*2, d_out, 3, 1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_2 = nn.Conv2d(d_out, d_out, 3, 1, padding=1)\n",
    "        \n",
    "\n",
    "    def forward(self, inp, a):\n",
    "        \n",
    "        x = self.relu(self.upconv(inp))\n",
    "        #x = self.upconv(inp)\n",
    "        if a is not None:\n",
    "            x = torch.cat([a, x], axis=1)\n",
    "            x = self.relu(self.conv_1(x))\n",
    "            \n",
    "        x = self.relu(self.conv_2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, filters, num_classes, simple=False, sigmoid=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder_blocks = []\n",
    "\n",
    "        for f in filters:\n",
    "            \n",
    "            if simple:\n",
    "                db = SimpleDecoderBlock(d_in, f)\n",
    "            else:\n",
    "                db = DecoderBlock(d_in, f)\n",
    "\n",
    "            self.decoder_blocks.append(db)\n",
    "            d_in = f\n",
    "        \n",
    "        self.output = nn.Conv2d(f, num_classes, 1, 1)\n",
    "        self.decoder_blocks = nn.ModuleList(self.decoder_blocks)\n",
    "        self.sig = nn.Sigmoid() if sigmoid else None\n",
    "    \n",
    "    def forward(self, inputs, activations):\n",
    "\n",
    "        x = inputs\n",
    "        for db, a in zip(self.decoder_blocks, activations):\n",
    "\n",
    "            x = db(x, a)\n",
    "        \n",
    "        output = self.output(x)\n",
    "        if self.sig is not None:\n",
    "            output = self.sig(output)\n",
    "\n",
    "\n",
    "        return output\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.C = in_channels\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=self.C, out_channels=self.C, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.C, out_channels=self.C, kernel_size=1, stride=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=self.C, out_channels=self.C, kernel_size=1, stride=1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "\n",
    "        H = x.shape[2]\n",
    "        W = x.shape[3]\n",
    "\n",
    "        N = H * W\n",
    "\n",
    "        a = x\n",
    "        b = self.conv1(x)\n",
    "        c = self.conv2(x)\n",
    "        d = self.conv3(x)\n",
    "\n",
    "        b = b.view(-1, self.C, N)\n",
    "        c = c.view(-1, self.C, N)\n",
    "        d = d.view(-1, self.C, N)\n",
    "\n",
    "        c = torch.bmm(c.transpose(1, 2), b)\n",
    "        S = nn.Softmax(dim=1)(c)\n",
    "        S = S.transpose(1, 2)\n",
    "\n",
    "        d = self.alpha * torch.bmm(d, S)\n",
    "        d = d.view(-1, self.C, H, W)\n",
    "        E = a + d\n",
    "\n",
    "        return E\n",
    "\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.beta = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "        self.C = in_channels\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        a1=a2=a3=a4 = x\n",
    "        H = x.shape[2]\n",
    "        W = x.shape[3]\n",
    "        N = H * W\n",
    "\n",
    "        a2 = a2.view(-1, self.C, N)\n",
    "        a3 = a3.view(-1, self.C, N)\n",
    "        a4 = a4.view(-1, self.C, N)\n",
    "        a4 = a4.transpose(1, 2)\n",
    "\n",
    "        aa_T = torch.bmm(a3, a4)\n",
    "        X = nn.Softmax(dim=1)(aa_T)\n",
    "        X = X.transpose(1, 2)\n",
    "\n",
    "        a2_pass = torch.bmm(X, a2) * self.beta\n",
    "        a2_pass = a2_pass.view(-1, self.C, H, W)\n",
    "\n",
    "        E = a1 + a2_pass\n",
    "\n",
    "        return E\n",
    "\n",
    "class DualAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "\n",
    "        super(DualAttention, self).__init__()\n",
    "        self.C = in_channels\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.C, self.C, 1)\n",
    "        self.conv2 = nn.Conv2d(self.C, self.C, 1)\n",
    "\n",
    "        self.sam = SpatialAttention(in_channels)\n",
    "        self.cam = ChannelAttention(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.sam(x)\n",
    "        e2 = self.sam(x)\n",
    "\n",
    "        e1 = self.conv1(e1)\n",
    "        e2 = self.conv2(e2)\n",
    "\n",
    "        F = e1 + e2\n",
    "        return F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSA(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        \n",
    "        super(CSA, self).__init__()\n",
    "\n",
    "        self.C = in_channels\n",
    "        self.C_by_2 = int(in_channels / 2)\n",
    "        self.conv_1 = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        self.conv_3x3_1 = nn.Conv2d(in_channels=self.C_by_2, out_channels=self.C_by_2, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv_3x3_2 = nn.Conv2d(in_channels=self.C_by_2, out_channels=self.C_by_2, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.conv_3x3_3 = nn.Conv2d(in_channels=in_channels, out_channels=self.C_by_2, kernel_size=3, stride=1, padding=\"same\")\n",
    "\n",
    "        self.group_1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=1, stride=1)\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.group_2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=1, stride=1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.final_conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        H = input.shape[2]\n",
    "        W = input.shape[3]\n",
    "\n",
    "        N = H * W\n",
    "\n",
    "        F = self.conv_1(input)\n",
    "        F_1, F_2 = F.split(int(self.C / 2), dim=1)\n",
    "\n",
    "        F_1 = self.conv_3x3_1(F_1)\n",
    "        F_2 = self.conv_3x3_2(F_2)\n",
    "        F_2 = torch.concat([F_1, F_2], dim=1)\n",
    "        F_2 = self.conv_3x3_3(F_2)\n",
    "\n",
    "        F = torch.concat([F_1, F_2], dim=1)\n",
    "\n",
    "        #Global average pooling\n",
    "        F = nn.AdaptiveAvgPool2d((H, W))(F)\n",
    "\n",
    "        F = self.group_1(F)\n",
    "        F = self.bn(F)\n",
    "        F = self.relu(F)\n",
    "        F = self.group_2(F)\n",
    "\n",
    "        F_1_s, F_2_s = F.split(int(self.C / 2), dim=1)\n",
    "\n",
    "        F_1_s = self.softmax(F_1)\n",
    "        F_2_s = self.softmax(F_2)\n",
    "\n",
    "        F_1_final = F_1 * F_1_s\n",
    "        F_2_final = F_2 * F_2_s\n",
    "\n",
    "        F_final = torch.concat([F_1_final, F_2_final], dim=1)\n",
    "        F_final = self.final_conv(F_final)\n",
    "\n",
    "        output = F_final + input\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "resnet_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "class ResNetUNet(nn.Module, BaseModel):\n",
    "\n",
    "    def __init__(self, num_classes, simple=False, sigmoid=False, attention=False):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.activations = [None]\n",
    "        resnet_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "        self.resnet_backbone = nn.Sequential(*(list(resnet_model.children())[0:7]))\n",
    "        for param in self.resnet_backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        filters = [512, 256, 64, 64]\n",
    "        self.decoder = Decoder(1024, filters, num_classes, simple, sigmoid)\n",
    "        self.attention = attention\n",
    "        if attention == 1:\n",
    "            self.attention = CSA(1024)\n",
    "            self.attention_2 = CSA(filters[0])\n",
    "        elif attention == 2:\n",
    "            self.attention = DualAttention(1024)\n",
    "            self.attention_2 = DualAttention(filters[0])\n",
    "        elif attention > 2 or attention < 0:\n",
    "            print(\"Attention can only be 0, 1, or 2\")\n",
    "            return -1\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def getActivations(self):\n",
    "        def hook(model, input, output):\n",
    "            self.activations.append(output)\n",
    "        return hook\n",
    "    \n",
    "    def forward(self, input):\n",
    "\n",
    "        self.activations = [None]\n",
    "\n",
    "        hr1 = self.resnet_backbone[2].register_forward_hook(self.getActivations())\n",
    "        hr2 = self.resnet_backbone[4][2].register_forward_hook(self.getActivations())\n",
    "        hr3 = self.resnet_backbone[5][-1].register_forward_hook(self.getActivations())\n",
    "\n",
    "        resnet_output = self.resnet_backbone(input)\n",
    "        \n",
    "        if self.attention:\n",
    "            resnet_output = self.attention(resnet_output)\n",
    "            self.activations[-1] = self.attention_2(self.activations[-1])\n",
    "\n",
    "        final_output = self.decoder(resnet_output, self.activations[::-1])\n",
    "\n",
    "        hr1.remove()\n",
    "        hr2.remove()\n",
    "        hr3.remove()\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ResNetUNet(5, True, False, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = resnet50(weights=ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_model, \"res.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m, \"./test_res.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = nn.Sequential(*list(m.children()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Decoder(\n",
       "    (output): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0): SimpleDecoderBlock(\n",
       "        (upconv): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "        (conv_1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "        (conv_2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (conv_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      )\n",
       "      (1): SimpleDecoderBlock(\n",
       "        (upconv): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "        (conv_1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "        (conv_2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (conv_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      )\n",
       "      (2): SimpleDecoderBlock(\n",
       "        (upconv): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "        (conv_1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "        (conv_2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (conv_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      )\n",
       "      (3): SimpleDecoderBlock(\n",
       "        (upconv): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "        (conv_1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "        (conv_2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "        (conv_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DualAttention(\n",
       "    (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (sam): SpatialAttention(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (cam): ChannelAttention()\n",
       "  )\n",
       "  (3): DualAttention(\n",
       "    (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (sam): SpatialAttention(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (cam): ChannelAttention()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condatorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99e5acb3856f6305f99fb5a2748a7d968f1ebcc7ceb39392309b10440f3adee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

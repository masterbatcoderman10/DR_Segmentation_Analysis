{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "import segmentation_models as sm\n",
    "import tensorflow_advanced_segmentation_models as tasm\n",
    "import numpy as np\n",
    "import visualkeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Attention\n",
    "\n",
    "This notebook will conduct tests using activations from the VGG Encoder to develop a dual attention module. Firstly the channel attention module will be built followed by the spatial attention module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(weights=\"imagenet\", include_top=False, input_shape=(512,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the blocks from the VGG network\n",
    "vgg_blocks = {\n",
    "    f\"block{n}\" : [layer for layer in vgg19.layers if f\"block{n}_conv\" in layer.name] for n in range(1, 6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_encoder_block(x, layers):\n",
    "    \"\"\"\n",
    "    This function passes an input through a set of conv layers from VGG19, returning the downsampled and convolved activation\n",
    "    \"\"\"\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    \n",
    "    addition = x\n",
    "    x = tf.keras.layers.MaxPooling2D((2,2), strides = 2)(x)\n",
    "    return (x, addition)\n",
    "\n",
    "def last_vgg_block(x, layers):\n",
    "\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_encoder_full(input, layer_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    This function creates the full encoder given a dictionary of layers from the VGG network, it returns the final activation \n",
    "    and a list of intermediate activations\n",
    "    \"\"\"\n",
    "\n",
    "    activations = []\n",
    "    x = input\n",
    "    for layer_name in list(layer_dict.keys())[:-1]:\n",
    "        x, a = vgg_encoder_block(x, layer_dict[layer_name])\n",
    "        activations.append(a)\n",
    "    \n",
    "    x = last_vgg_block(x, layer_dict[list(layer_dict.keys())[-1]])\n",
    "    \n",
    "    return x, activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = vgg19.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, a = vgg_encoder_full(inp, vgg_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 512, 512, 64) dtype=float32 (created by layer 'block1_conv2')>,\n",
       " <KerasTensor: shape=(None, 256, 256, 128) dtype=float32 (created by layer 'block2_conv2')>,\n",
       " <KerasTensor: shape=(None, 128, 128, 256) dtype=float32 (created by layer 'block3_conv4')>,\n",
       " <KerasTensor: shape=(None, 64, 64, 512) dtype=float32 (created by layer 'block4_conv4')>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activation = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 512, 512, 64) dtype=float32 (created by layer 'block1_conv2')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Attention\n",
    "\n",
    "![](channel_attention.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplication of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=a2=a3=a4= test_activation\n",
    "H = a2.shape[1]\n",
    "W = a2.shape[2]\n",
    "C = a2.shape[3]\n",
    "a2 = tf.keras.layers.Reshape((H*W, C))(a2)\n",
    "a3 = tf.keras.layers.Reshape((H*W, C))(a3)\n",
    "a4 = tf.transpose(tf.keras.layers.Reshape((H*W, C))(a4), perm=[0,2,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing the Softmax Output X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_T_a = tf.linalg.matmul(a4, a3)\n",
    "x = tf.keras.layers.Softmax()(a_T_a)\n",
    "x = tf.transpose(x, perm=[0,2,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing E - the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_pass = tf.linalg.matmul(a2, x)\n",
    "a2_pass = tf.keras.layers.Reshape((H,W,C))(a2_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = tf.keras.layers.Add()([a1, a2_pass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 512, 512, 64) dtype=float32 (created by layer 'add')>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function of the Channel-Attention-Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam(inputs):\n",
    "\n",
    "    a1=a2=a3=a4= inputs\n",
    "    H = a2.shape[1]\n",
    "    W = a2.shape[2]\n",
    "    C = a2.shape[3]\n",
    "    a2 = tf.keras.layers.Reshape((H*W, C))(a2)\n",
    "    a3 = tf.keras.layers.Reshape((H*W, C))(a3)\n",
    "    a4 = tf.transpose(tf.keras.layers.Reshape((H*W, C))(a4), perm=[0,2,1])\n",
    "\n",
    "\n",
    "    #Creating X, the softmax on the matrix product of A_T_A\n",
    "    a_T_a = tf.linalg.matmul(a4, a3)\n",
    "    x = tf.keras.layers.Softmax()(a_T_a)\n",
    "    x = tf.transpose(x, perm=[0,2,1])\n",
    "\n",
    "    a2_pass = tf.linalg.matmul(a2, x)\n",
    "    a2_pass = tf.keras.layers.Reshape((H,W,C))(a2_pass)\n",
    "\n",
    "    E = tf.keras.layers.Add()([a1, a2_pass])\n",
    "\n",
    "    return E\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 512, 512, 64) dtype=float32 (created by layer 'add_1')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = cam(test_activation)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer for Channel Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.beta = tf.Variable(initial_value=0.0, name=\"beta\", trainable=True)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.C = input_shape[-1]\n",
    "        self.H = input_shape[1]\n",
    "        self.W = input_shape[2]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        a1=a2=a3=a4= inputs\n",
    "        n_shape = self.H * self.W\n",
    "        a2 = tf.keras.layers.Reshape((n_shape, self.C))(a2)\n",
    "        a3 = tf.keras.layers.Reshape((n_shape, self.C))(a3)\n",
    "        a4 = tf.transpose(tf.keras.layers.Reshape((n_shape, self.C))(a4), perm=[0,2,1])\n",
    "\n",
    "\n",
    "        #Creating X, the softmax on the matrix product of A_T_A\n",
    "        a_T_a = tf.linalg.matmul(a4, a3)\n",
    "        x = tf.keras.layers.Softmax()(a_T_a)\n",
    "        x = tf.transpose(x, perm=[0,2,1])\n",
    "\n",
    "        a2_pass = self.beta * tf.linalg.matmul(a2, x)\n",
    "        a2_pass = tf.keras.layers.Reshape((self.H,self.W,self.C))(a2_pass)\n",
    "\n",
    "        E = tf.keras.layers.Add()([a1, a2_pass])\n",
    "\n",
    "        return E\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ChannelAttention()(test_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Attention Module\n",
    "\n",
    "The spatial attention module will be constructed in the same spirit as the channel attention module.\n",
    "\n",
    "![](spatial_attention.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.alpha = tf.Variable(initial_value=0.0, trainable=True)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.C = input_shape[-1]\n",
    "        self.H = input_shape[1]\n",
    "        self.W = input_shape[2]\n",
    "\n",
    "        #Defining the convolutions\n",
    "        self.conv1 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        n_shape = self.H * self.W\n",
    "\n",
    "        a = inputs\n",
    "        b = self.conv1(inputs)\n",
    "        c = self.conv2(inputs)\n",
    "        d = self.conv3(inputs)\n",
    "\n",
    "        b = tf.transpose(tf.keras.layers.Reshape((n_shape, self.C))(b), perm=[0,2,1])\n",
    "        c = tf.keras.layers.Reshape((n_shape, self.C))(c)\n",
    "        d = tf.keras.layers.Reshape((n_shape, self.C))(d)\n",
    "\n",
    "        c = tf.linalg.matmul(c, b)\n",
    "        S = tf.keras.layers.Softmax()(c)\n",
    "        S = tf.transpose(S, perm=[0,2,1])\n",
    "\n",
    "        d = self.alpha * tf.linalg.matmul(S, d)\n",
    "        d = tf.keras.layers.Reshape((self.H, self.W, self.C))(d)\n",
    "        E = tf.keras.layers.Add()([a, d])        \n",
    "\n",
    "        return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = SpatialAttention()(test_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 512, 512, 64) dtype=float32 (created by layer 'spatial_attention')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Attention Module\n",
    "\n",
    "The dual attention module applies a convolution to the outputs of the spatial and channel attention modules, then applies an elementwise sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DualAttention, self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.C = input_shape[-1]\n",
    "        self.conv1 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "        self.sam = SpatialAttention()\n",
    "        self.cam = ChannelAttention()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        e1 = self.sam(inputs)\n",
    "        e2 = self.cam(inputs)\n",
    "\n",
    "        e1 = self.conv1(e1)\n",
    "        e2 = self.conv2(e2)\n",
    "\n",
    "        F = tf.keras.layers.Add()([e1, e2])\n",
    "        return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 512, 512, 64) dtype=float32 (created by layer 'block1_conv2')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = DualAttention()(test_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 512, 512, 64) dtype=float32 (created by layer 'dual_attention')>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.array([1 , 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ar[ar>3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing The Incorporation of the Dual Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(a, x, f, attention=False):\n",
    "\n",
    "    if attention:\n",
    "        a = DualAttention()(a)\n",
    "\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=f, kernel_size=2, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
    "    if a is not  None:\n",
    "        x = tf.concat([a, x], axis=-1)\n",
    "    x = tf.keras.layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\")(x) \n",
    "\n",
    "    return x\n",
    "\n",
    "def decoder_full(activations, x, filters, num_classes, attention_indices):\n",
    "\n",
    "    #Looping over the activations and filters from bottom to top\n",
    "    #Activation are reversed for this effect\n",
    "\n",
    "\n",
    "        #Flag to indicate that there is no need for attention\n",
    "    \n",
    "    ai = None\n",
    "    #Flag to indicate whether the point of attention is found\n",
    "    found = True\n",
    "    #Flag to pass to the decoder block, whether dual attention should be applied\n",
    "    att = False\n",
    "    for i,(a,f) in enumerate(zip(activations[::-1],filters)):\n",
    "        there = len(attention_indices)\n",
    "        if found and there:\n",
    "            ai = attention_indices.pop()\n",
    "        \n",
    "        #Check if the current activation needs attention\n",
    "\n",
    "        att=found = (i+1 == ai)\n",
    "        print(att)\n",
    "        x = decoder_block(a, x, f, att)\n",
    "    \n",
    "    output = tf.keras.layers.Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_encoder_block(x, layers):\n",
    "    \"\"\"\n",
    "    This function passes an input through a set of conv layers from VGG19, returning the downsampled and convolved activation\n",
    "    \"\"\"\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    \n",
    "    addition = x\n",
    "    x = tf.keras.layers.MaxPooling2D((2,2), strides = 2)(x)\n",
    "    return (x, addition)\n",
    "\n",
    "def last_vgg_block(x, layers):\n",
    "\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def vgg_encoder_full(input, layer_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    This function creates the full encoder given a dictionary of layers from the VGG network, it returns the final activation \n",
    "    and a list of intermediate activations\n",
    "    \"\"\"\n",
    "\n",
    "    activations = []\n",
    "    x = input\n",
    "    for layer_name in list(layer_dict.keys())[:-1]:\n",
    "        x, a = vgg_encoder_block(x, layer_dict[layer_name])\n",
    "        activations.append(a)\n",
    "    \n",
    "    x = last_vgg_block(x, layer_dict[list(layer_dict.keys())[-1]])\n",
    "    \n",
    "    return x, activations\n",
    "\n",
    "\n",
    "\n",
    "def vgg_unet(num_classes, input_size, input_dim, att_indices=[], last_attention=False):\n",
    "\n",
    "    #Downloading the VGG network\n",
    "    vgg19 = VGG19(weights=\"imagenet\", include_top=False, input_shape=(input_size, input_size,input_dim))\n",
    "    vgg19.trainable = False\n",
    "    #Getting all the blocks from the VGG network\n",
    "    vgg_blocks = {\n",
    "        f\"block{n}\" : [layer for layer in vgg19.layers if f\"block{n}_conv\" in layer.name] for n in range(1, 6)\n",
    "    }\n",
    "    \n",
    "    #Filters for the Decoder\n",
    "    filters = [512, 256, 128, 64]\n",
    "\n",
    "    l = len(att_indices)\n",
    "    assert l >= 0, \"Attention indices should be 0 or greater\"\n",
    "    assert l <= len(filters) + 1, \"Number of layers for attetention can not exceed 5\"\n",
    "\n",
    "    #assert len(att_indices[att_indices > 5]) == 0, \"Attention indices must be from 1 to 5\"\n",
    "    \n",
    "\n",
    "    vgg_input = vgg19.input\n",
    "\n",
    "    #Defining the encoder\n",
    "\n",
    "    #First Preprocess the input\n",
    "    x = preprocess_input(x=vgg_input)\n",
    "    \n",
    "    x, a = vgg_encoder_full(x, vgg_blocks)\n",
    "\n",
    "    if last_attention:\n",
    "        x = DualAttention()(x)\n",
    "\n",
    "    output = decoder_full(a, x, filters, num_classes, att_indices)\n",
    "\n",
    "    vgg_unet_model = tf.keras.Model(vgg_input, output)\n",
    "\n",
    "    return vgg_unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "m = vgg_unet(5, 512, 3, [2], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "visualkeras.layered_view(m, scale_xy=1, legend=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 512, 512, 3)  0          ['input_2[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.bias_add (TFOpLambda)    (None, 512, 512, 3)  0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 512, 512, 64  1792        ['tf.nn.bias_add[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 512, 512, 64  36928       ['block1_conv1[1][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 256, 256, 64  0          ['block1_conv2[1][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 256, 256, 12  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 256, 256, 12  147584      ['block2_conv1[1][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 12  0          ['block2_conv2[1][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 128, 128, 25  295168      ['max_pooling2d_5[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv1[1][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv2[1][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv4 (Conv2D)          (None, 128, 128, 25  590080      ['block3_conv3[1][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 256)  0          ['block3_conv4[1][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 64, 64, 512)  1180160     ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv1[1][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv2[1][0]']           \n",
      "                                                                                                  \n",
      " block4_conv4 (Conv2D)          (None, 64, 64, 512)  2359808     ['block4_conv3[1][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 512)  0          ['block4_conv4[1][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 32, 32, 512)  2359808     ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv1[1][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv2[1][0]']           \n",
      "                                                                                                  \n",
      " block5_conv4 (Conv2D)          (None, 32, 32, 512)  2359808     ['block5_conv3[1][0]']           \n",
      "                                                                                                  \n",
      " dual_attention_1 (DualAttentio  (None, 32, 32, 512)  1313282    ['block5_conv4[1][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " dual_attention_2 (DualAttentio  (None, 64, 64, 512)  1313282    ['block4_conv4[1][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  1049088    ['dual_attention_1[0][0]']       \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 64, 64, 1024  0           ['dual_attention_2[0][0]',       \n",
      "                                )                                 'conv2d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 64, 512)  4719104     ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 512)  2359808     ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['conv2d_1[0][0]']               \n",
      " spose)                         6)                                                                \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 128, 128, 51  0           ['block3_conv4[1][0]',           \n",
      "                                2)                                'conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 25  1179904     ['tf.concat_1[0][0]']            \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 25  590080      ['conv2d_2[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['conv2d_3[0][0]']               \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 256, 256, 25  0           ['block2_conv2[1][0]',           \n",
      "                                6)                                'conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 256, 256, 12  295040      ['tf.concat_2[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 256, 256, 12  147584      ['conv2d_4[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['conv2d_5[0][0]']               \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 512, 512, 12  0           ['block1_conv2[1][0]',           \n",
      "                                8)                                'conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 512, 512, 64  73792       ['tf.concat_3[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 512, 512, 64  36928       ['conv2d_6[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 512, 512, 5)  325         ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33,791,177\n",
      "Trainable params: 13,766,793\n",
      "Non-trainable params: 20,024,384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db96c7c19d6ddb955ec6ab14ba350af8085dd720a16eea0a08edd8c99e1901ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "import segmentation_models as sm\n",
    "import tensorflow_advanced_segmentation_models as tasm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Attention\n",
    "\n",
    "This notebook will conduct tests using activations from the VGG Encoder to develop a dual attention module. Firstly the channel attention module will be built followed by the spatial attention module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(weights=\"imagenet\", include_top=False, input_shape=(512,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all the blocks from the VGG network\n",
    "vgg_blocks = {\n",
    "    f\"block{n}\" : [layer for layer in vgg19.layers if f\"block{n}_conv\" in layer.name] for n in range(1, 6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_encoder_block(x, layers):\n",
    "    \"\"\"\n",
    "    This function passes an input through a set of conv layers from VGG19, returning the downsampled and convolved activation\n",
    "    \"\"\"\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    \n",
    "    addition = x\n",
    "    x = tf.keras.layers.MaxPooling2D((2,2), strides = 2)(x)\n",
    "    return (x, addition)\n",
    "\n",
    "def last_vgg_block(x, layers):\n",
    "\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_encoder_full(input, layer_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    This function creates the full encoder given a dictionary of layers from the VGG network, it returns the final activation \n",
    "    and a list of intermediate activations\n",
    "    \"\"\"\n",
    "\n",
    "    activations = []\n",
    "    x = input\n",
    "    for layer_name in list(layer_dict.keys())[:-1]:\n",
    "        x, a = vgg_encoder_block(x, layer_dict[layer_name])\n",
    "        activations.append(a)\n",
    "    \n",
    "    x = last_vgg_block(x, layer_dict[list(layer_dict.keys())[-1]])\n",
    "    \n",
    "    return x, activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = vgg19.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, a = vgg_encoder_full(inp, vgg_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 512, 512, 64) dtype=float32 (created by layer 'block1_conv2')>,\n",
       " <KerasTensor: shape=(None, 256, 256, 128) dtype=float32 (created by layer 'block2_conv2')>,\n",
       " <KerasTensor: shape=(None, 128, 128, 256) dtype=float32 (created by layer 'block3_conv4')>,\n",
       " <KerasTensor: shape=(None, 64, 64, 512) dtype=float32 (created by layer 'block4_conv4')>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activation = a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Attention\n",
    "\n",
    "![](channel_attention.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplication of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=a2=a3=a4= test_activation\n",
    "H = a2.shape[1]\n",
    "W = a2.shape[2]\n",
    "C = a2.shape[3]\n",
    "a2 = tf.keras.layers.Reshape((H*W, C))(a2)\n",
    "a3 = tf.keras.layers.Reshape((H*W, C))(a3)\n",
    "a4 = tf.transpose(tf.keras.layers.Reshape((H*W, C))(a4), perm=[0,2,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing the Softmax Output X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_T_a = tf.linalg.matmul(a4, a3)\n",
    "x = tf.keras.layers.Softmax()(a_T_a)\n",
    "x = tf.transpose(x, perm=[0,2,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing E - the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_pass = tf.linalg.matmul(a2, x)\n",
    "a2_pass = tf.keras.layers.Reshape((H,W,C))(a2_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = tf.keras.layers.Add()([a1, a2_pass])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function of the Channel-Attention-Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam(inputs):\n",
    "\n",
    "    a1=a2=a3=a4= inputs\n",
    "    H = a2.shape[1]\n",
    "    W = a2.shape[2]\n",
    "    C = a2.shape[3]\n",
    "    a2 = tf.keras.layers.Reshape((H*W, C))(a2)\n",
    "    a3 = tf.keras.layers.Reshape((H*W, C))(a3)\n",
    "    a4 = tf.transpose(tf.keras.layers.Reshape((H*W, C))(a4), perm=[0,2,1])\n",
    "\n",
    "\n",
    "    #Creating X, the softmax on the matrix product of A_T_A\n",
    "    a_T_a = tf.linalg.matmul(a4, a3)\n",
    "    x = tf.keras.layers.Softmax()(a_T_a)\n",
    "    x = tf.transpose(x, perm=[0,2,1])\n",
    "\n",
    "    a2_pass = tf.linalg.matmul(a2, x)\n",
    "    a2_pass = tf.keras.layers.Reshape((H,W,C))(a2_pass)\n",
    "\n",
    "    E = tf.keras.layers.Add()([a1, a2_pass])\n",
    "\n",
    "    return E\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 128, 256) dtype=float32 (created by layer 'add_5')>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = cam(test_activation)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer for Channel Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.beta = tf.Variable(initial_value=0.0, name=\"beta\", trainable=True)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.C = input_shape[-1]\n",
    "        self.H = input_shape[1]\n",
    "        self.W = input_shape[2]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        a1=a2=a3=a4= inputs\n",
    "        n_shape = self.H * self.W\n",
    "        a2 = tf.keras.layers.Reshape((n_shape, self.C))(a2)\n",
    "        a3 = tf.keras.layers.Reshape((n_shape, self.C))(a3)\n",
    "        a4 = tf.transpose(tf.keras.layers.Reshape((n_shape, self.C))(a4), perm=[0,2,1])\n",
    "\n",
    "\n",
    "        #Creating X, the softmax on the matrix product of A_T_A\n",
    "        a_T_a = tf.linalg.matmul(a4, a3)\n",
    "        x = tf.keras.layers.Softmax()(a_T_a)\n",
    "        x = tf.transpose(x, perm=[0,2,1])\n",
    "\n",
    "        a2_pass = self.beta * tf.linalg.matmul(a2, x)\n",
    "        a2_pass = tf.keras.layers.Reshape((self.H,self.W,self.C))(a2_pass)\n",
    "\n",
    "        E = tf.keras.layers.Add()([a1, a2_pass])\n",
    "\n",
    "        return E\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ChannelAttention()(test_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Attention Module\n",
    "\n",
    "The spatial attention module will be constructed in the same spirit as the channel attention module.\n",
    "\n",
    "![](spatial_attention.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.alpha = tf.Variable(initial_value=0.0, trainable=True)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.C = input_shape[-1]\n",
    "        self.H = input_shape[1]\n",
    "        self.W = input_shape[2]\n",
    "\n",
    "        #Defining the convolutions\n",
    "        self.conv1 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        n_shape = self.H * self.W\n",
    "\n",
    "        a = inputs\n",
    "        b = self.conv1(inputs)\n",
    "        c = self.conv2(inputs)\n",
    "        d = self.conv3(inputs)\n",
    "\n",
    "        b = tf.transpose(tf.keras.layers.Reshape((n_shape, self.C))(b), perm=[0,2,1])\n",
    "        c = tf.keras.layers.Reshape((n_shape, self.C))(c)\n",
    "        d = tf.keras.layers.Reshape((n_shape, self.C))(d)\n",
    "\n",
    "        c = tf.linalg.matmul(c, b)\n",
    "        S = tf.keras.layers.Softmax()(c)\n",
    "        S = tf.transpose(S, perm=[0,2,1])\n",
    "\n",
    "        d = self.alpha * tf.linalg.matmul(S, d)\n",
    "        d = tf.keras.layers.Reshape((self.H, self.W, self.C))(d)\n",
    "        E = tf.keras.layers.Add()([a, d])        \n",
    "\n",
    "        return E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = SpatialAttention()(test_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 128, 256) dtype=float32 (created by layer 'spatial_attention_2')>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Attention Module\n",
    "\n",
    "The dual attention module applies a convolution to the outputs of the spatial and channel attention modules, then applies an elementwise sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DualAttention, self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.C = input_shape[-1]\n",
    "        self.conv1 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(self.C, 1)\n",
    "        self.sam = SpatialAttention()\n",
    "        self.cam = ChannelAttention()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        e1 = self.sam(inputs)\n",
    "        e2 = self.cam(inputs)\n",
    "\n",
    "        e1 = self.conv1(e1)\n",
    "        e2 = self.conv2(e2)\n",
    "\n",
    "        F = tf.keras.layers.Add()([e1, e2])\n",
    "        return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = DualAttention()(test_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 128, 256) dtype=float32 (created by layer 'dual_attention_1')>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db96c7c19d6ddb955ec6ab14ba350af8085dd720a16eea0a08edd8c99e1901ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

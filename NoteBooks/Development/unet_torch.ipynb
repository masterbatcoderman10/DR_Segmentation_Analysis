{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhtar/opt/anaconda3/envs/condatorch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(d_in, d_out, 3, 1, \"same\"),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(d_out, d_out, 3, 1, \"same\"),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "\n",
    "        a = self.conv_1(inputs)\n",
    "        a = self.conv_2(a)\n",
    "        x = self.pool(a)\n",
    "        x = self.conv_2(x)\n",
    "\n",
    "        return x, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "\n",
    "        super(LastEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(d_in, d_out, 3, 1, \"same\"),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(d_out, d_out, 3, 1, \"same\"),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        x = self.conv2(self.conv1(inputs))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, filters):\n",
    "\n",
    "        super(FullEncoder, self).__init__()\n",
    "\n",
    "        self.encoder_blocks = []\n",
    "        for f in filters[:-1]:\n",
    "\n",
    "            encoder = EncoderBlock(d_in, f)\n",
    "            self.encoder_blocks.append(encoder)\n",
    "            d_in = f\n",
    "        \n",
    "        self.last_encoder = LastEncoder(f, filters[-1])\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        activations = []\n",
    "        x = inputs\n",
    "        for eb in self.encoder_blocks:\n",
    "            x, a = eb(x)\n",
    "            activations.append(a)\n",
    "        \n",
    "        x = self.last_encoder(x)\n",
    "\n",
    "        return x, activations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_encoder = FullEncoder(3, [64, 128, 256, 512, 1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder for the U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(d_in, d_out, 2, 2, padding=\"same\"),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(d_out, d_out, 3, 1, padding=\"same\"),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, inp, a):\n",
    "\n",
    "        x = self.upconv(inp)\n",
    "        if a is not None:\n",
    "            x = torch.cat([a, x], axis=-1)\n",
    "        \n",
    "        x = self.conv(self.conv(x))\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, filters, num_classes):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder_blocks = []\n",
    "\n",
    "        for f in filters:\n",
    "\n",
    "            self.db = DecoderBlock(d_in, f)\n",
    "            self.decoder_blocks.append(self.db)\n",
    "            d_in = f\n",
    "        \n",
    "        self.output = nn.Conv2d(f, num_classes, 1, 1)\n",
    "    \n",
    "    def forward(self, inputs, activations):\n",
    "\n",
    "        x = inputs\n",
    "        for db, a in zip(self.decoder_blocks, activations):\n",
    "\n",
    "            x = db(x, a)\n",
    "        \n",
    "        output = self.output(x)\n",
    "\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, num_classes, filters):\n",
    "\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = FullEncoder(d_in, filters[:-1])\n",
    "\n",
    "        self.decoder = Decoder(d_in, filters[:-1][::-1], num_classes)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "\n",
    "        x, activations = self.encoder(inputs)\n",
    "\n",
    "        o = self.decoder(x, activations[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(3, 5, [64, 128, 256, 512, 1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333332538604736"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "\n",
    "gt = torch.Tensor([[0,0,0],[0,1,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0]])\n",
    "pred = torch.Tensor([[0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0], [0,0,0]])\n",
    "\n",
    "gt = torch.reshape(gt, (-1,))\n",
    "pred = torch.reshape(pred, (-1,))\n",
    "\n",
    "l = loss(gt, pred)\n",
    "l.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(network, data, epochs, batch_size,loss_function, optimizer, log=True, device=\"cuda\"):\n",
    "\n",
    "    \"\"\"\n",
    "    This function implements for the training of a deep neural network : Per epoch, iterate over all the batches, for each batch compute the outpus, compute the loss with the ground truth, update the model parameters using the gradients.\n",
    "    network : The network to train, it is expected that the forward function will be implemented\n",
    "    data : Already prebatched data : image data and the annotations (images, annotations)\n",
    "    epochs : Number of epochs\n",
    "    loss : the initialized loss function\n",
    "    optimizer : the optimizer alogirthm to update the model parameters, should be initialized with model parameters\n",
    "    \"\"\"\n",
    "    images, annotations = data\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        elapsed_time = 0\n",
    "        st = time.time()\n",
    "        loss_value = 0\n",
    "        \n",
    "        for img_batch, annotation_batch in zip(images, annotations):\n",
    "\n",
    "            img_batch = img_batch.to(device)\n",
    "            annotation_batch = annotation_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #mMake model prediction\n",
    "            pred = network(img_batch)\n",
    "\n",
    "            #Reshape predictions and ground truth to linear\n",
    "            #pred = torch.reshape(pred, (-1,))\n",
    "            #gt = torch.reshape(annotation_batch, (-1,))\n",
    "\n",
    "            #Compute Loss\n",
    "            loss = loss_function(gt, pred)\n",
    "\n",
    "            #Calculate gradients through backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            #Update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_value += loss.item()\n",
    "        if log:\n",
    "            print(f\"Loss at epoch : {e} : {round(loss_value / batch_size, 3)}\")\n",
    "        et = time.time()\n",
    "        elapsed_time = et - st\n",
    "        print(f\"Epoch : {e} took {elapsed_time} seconds\")\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('condatorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99e5acb3856f6305f99fb5a2748a7d968f1ebcc7ceb39392309b10440f3adee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
